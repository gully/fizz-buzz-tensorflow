{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments with TensorFlow\n",
    "\n",
    "gully\n",
    "\n",
    "June 30, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime number example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adapted from:  \n",
    "fizz_buzz.py  \n",
    "Fizz Buzz in Tensorflow!  \n",
    "see http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "# Represent each input by an array of its binary digits.\n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a prime number checker and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prime_encode(n):\n",
    "    if (n == 2) or (n == 3): return [1, 0]\n",
    "    if n < 2 or n%2 == 0: return [0, 1]\n",
    "    if n < 9: return [1, 0]\n",
    "    if n%3 == 0: return [0, 1]\n",
    "    r = int(n**0.5)\n",
    "    f = 5\n",
    "    while f <= r:\n",
    "        if n%f == 0: return [0, 1]\n",
    "        if n%(f+2) == 0: return [0, 1]\n",
    "        f +=6\n",
    "    return [1, 0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    " Our goal is to produce prime numbers for the numbers 1 to 100. So it would be unfair to include these in our training data.  \n",
    " Accordingly, the training data corresponds to the numbers 101 to `(2 ** NUM_DIGITS - 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX = np.array([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DIGITS)])\n",
    "trY = np.array([prime_encode(i)          for i in range(101, 2 ** NUM_DIGITS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 10), (923, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll want to randomly initialize weights.\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is a standard 1-hidden-layer multi-layer-perceptron with ReLU activation.  \n",
    "The softmax (which turns arbitrary real-valued outputs into probabilities) gets applied in the cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    return tf.matmul(h, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our variables. The input has width NUM_DIGITS, and the output has width 4.\n",
    "X = tf.placeholder(\"float\", [None, NUM_DIGITS])\n",
    "Y = tf.placeholder(\"float\", [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(10)]),\n",
       " TensorShape([Dimension(None), Dimension(2)]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.get_shape(), Y.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many units in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 100\n",
    "\n",
    "# Initialize the weights.\n",
    "w_h = init_weights([NUM_DIGITS, NUM_HIDDEN])\n",
    "w_o = init_weights([NUM_HIDDEN, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(10), Dimension(100)]),\n",
       " TensorShape([Dimension(100), Dimension(2)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_h.get_shape(), w_o.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict y given x using the model.\n",
    "py_x = model(X, w_h, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_x.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train our model by minimizing a cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll make predictions by choosing the largest output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check against the correct answer, since we know it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance-- we know the correct answer after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_answer = [\"{}\".format(np.array(['prime', i])[np.array([bool(el) for el in prime_encode(i)])][0])\n",
    " for i in np.arange(1,101)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prime(i, prediction):\n",
    "    return [\"prime\", str(i)][prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 0.841 27\n",
      "0500 0.841 25\n",
      "1000 0.841 25\n",
      "1500 0.860 25\n",
      "2000 0.872 25\n",
      "2500 0.899 25\n",
      "3000 0.914 25\n",
      "3500 0.940 22\n",
      "4000 0.940 23\n",
      "4500 0.962 24\n",
      "5000 0.983 23\n",
      "5500 0.984 23\n",
      "6000 0.961 22\n",
      "6500 1.000 22\n",
      "7000 1.000 23\n",
      "7500 1.000 24\n",
      "8000 1.000 22\n",
      "8500 1.000 19\n",
      "9000 1.000 21\n",
      "9500 1.000 21\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for epoch in range(10000):\n",
    "        # Shuffle the data before each training iteration.\n",
    "        p = np.random.permutation(range(len(trX)))\n",
    "        trX, trY = trX[p], trY[p]\n",
    "\n",
    "        # Train in batches of 128 inputs.\n",
    "        for start in range(0, len(trX), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "        # And print the current accuracy on the training data.\n",
    "        val = np.mean(np.argmax(trY, axis=1) ==\n",
    "                             sess.run(predict_op, feed_dict={X: trX, Y: trY}))\n",
    "\n",
    "        # And now for some fizz buzz\n",
    "        numbers = np.arange(1, 101)\n",
    "        teX = np.transpose(binary_encode(numbers, NUM_DIGITS))\n",
    "        teY = sess.run(predict_op, feed_dict={X: teX})\n",
    "        output = np.vectorize(prime)(numbers, teY)\n",
    "\n",
    "        if (epoch % 500) == 0:\n",
    "            print(\"{:04d}\".format(epoch), \n",
    "                  \"{:0.3f}\".format(val), \n",
    "                  \"{: >2d}\".format((output != correct_answer).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Correct\" answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_answer = [\"{}\".format(np.array(['prime', i])[np.array([bool(el) for el in prime_encode(i)])][0])\n",
    " for i in np.arange(1,101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['prime', '1'],\n",
       "       ['2', 'prime'],\n",
       "       ['prime', 'prime'],\n",
       "       ['4', '4'],\n",
       "       ['prime', 'prime'],\n",
       "       ['6', '6'],\n",
       "       ['prime', 'prime'],\n",
       "       ['8', '8'],\n",
       "       ['prime', '9'],\n",
       "       ['10', '10'],\n",
       "       ['prime', 'prime'],\n",
       "       ['12', '12'],\n",
       "       ['prime', 'prime'],\n",
       "       ['14', '14'],\n",
       "       ['15', '15'],\n",
       "       ['16', '16'],\n",
       "       ['prime', 'prime'],\n",
       "       ['18', '18'],\n",
       "       ['19', 'prime'],\n",
       "       ['20', '20'],\n",
       "       ['prime', '21'],\n",
       "       ['22', '22'],\n",
       "       ['23', 'prime'],\n",
       "       ['24', '24'],\n",
       "       ['prime', '25'],\n",
       "       ['26', '26'],\n",
       "       ['27', '27'],\n",
       "       ['28', '28'],\n",
       "       ['prime', 'prime'],\n",
       "       ['30', '30'],\n",
       "       ['prime', 'prime'],\n",
       "       ['32', '32'],\n",
       "       ['33', '33'],\n",
       "       ['34', '34'],\n",
       "       ['prime', '35'],\n",
       "       ['36', '36'],\n",
       "       ['prime', 'prime'],\n",
       "       ['38', '38'],\n",
       "       ['39', '39'],\n",
       "       ['40', '40'],\n",
       "       ['prime', 'prime'],\n",
       "       ['42', '42'],\n",
       "       ['prime', 'prime'],\n",
       "       ['44', '44'],\n",
       "       ['45', '45'],\n",
       "       ['46', '46'],\n",
       "       ['47', 'prime'],\n",
       "       ['48', '48'],\n",
       "       ['prime', '49'],\n",
       "       ['50', '50'],\n",
       "       ['prime', '51'],\n",
       "       ['52', '52'],\n",
       "       ['prime', 'prime'],\n",
       "       ['54', '54'],\n",
       "       ['prime', '55'],\n",
       "       ['56', '56'],\n",
       "       ['prime', '57'],\n",
       "       ['58', '58'],\n",
       "       ['prime', 'prime'],\n",
       "       ['60', '60'],\n",
       "       ['prime', 'prime'],\n",
       "       ['62', '62'],\n",
       "       ['63', '63'],\n",
       "       ['64', '64'],\n",
       "       ['prime', '65'],\n",
       "       ['66', '66'],\n",
       "       ['prime', 'prime'],\n",
       "       ['68', '68'],\n",
       "       ['prime', '69'],\n",
       "       ['70', '70'],\n",
       "       ['prime', 'prime'],\n",
       "       ['72', '72'],\n",
       "       ['prime', 'prime'],\n",
       "       ['74', '74'],\n",
       "       ['75', '75'],\n",
       "       ['76', '76'],\n",
       "       ['77', '77'],\n",
       "       ['78', '78'],\n",
       "       ['79', 'prime'],\n",
       "       ['80', '80'],\n",
       "       ['prime', '81'],\n",
       "       ['82', '82'],\n",
       "       ['83', 'prime'],\n",
       "       ['84', '84'],\n",
       "       ['85', '85'],\n",
       "       ['86', '86'],\n",
       "       ['87', '87'],\n",
       "       ['88', '88'],\n",
       "       ['89', 'prime'],\n",
       "       ['90', '90'],\n",
       "       ['prime', '91'],\n",
       "       ['92', '92'],\n",
       "       ['93', '93'],\n",
       "       ['94', '94'],\n",
       "       ['95', '95'],\n",
       "       ['96', '96'],\n",
       "       ['prime', 'prime'],\n",
       "       ['98', '98'],\n",
       "       ['prime', '99'],\n",
       "       ['100', '100']], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([output, correct_answer]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fails = output != correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['prime', '1'],\n",
       "       ['2', 'prime'],\n",
       "       ['prime', '9'],\n",
       "       ['19', 'prime'],\n",
       "       ['prime', '21'],\n",
       "       ['23', 'prime'],\n",
       "       ['prime', '25'],\n",
       "       ['prime', '35'],\n",
       "       ['47', 'prime'],\n",
       "       ['prime', '49'],\n",
       "       ['prime', '51'],\n",
       "       ['prime', '55'],\n",
       "       ['prime', '57'],\n",
       "       ['prime', '65'],\n",
       "       ['prime', '69'],\n",
       "       ['79', 'prime'],\n",
       "       ['prime', '81'],\n",
       "       ['83', 'prime'],\n",
       "       ['89', 'prime'],\n",
       "       ['prime', '91'],\n",
       "       ['prime', '99']], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([output[fails], np.array(correct_answer)[fails]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prime number example has much worse performance than the FizzBuzz example.  \n",
    "This probably has some deep explanation from math and neural networks-- prime numbers are unpredictable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
